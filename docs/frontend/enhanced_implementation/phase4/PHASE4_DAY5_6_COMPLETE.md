# Phase 4 Day 5-6: Evaluation Harness System ì™„ë£Œ ë¦¬í¬íŠ¸

**ì¼ì**: 2025-01-XX  
**ëª©í‘œ**: Evaluation Harness System - ëª¨ë¸ í‰ê°€, ë²¤ì¹˜ë§ˆí‚¹, A/B í…ŒìŠ¤íŒ…, ê³µì •ì„±
ê°ì‚¬  
**ìƒíƒœ**: âœ… **100% ì™„ë£Œ** (2,451 lines)

---

## ğŸ“Š êµ¬í˜„ ìš”ì•½

### ì´ ì½”ë“œ í†µê³„

- **ì´ ë¼ì¸ ìˆ˜**: 2,451 lines
- **í›…**: 1ê°œ (816 lines)
- **ì»´í¬ë„ŒíŠ¸**: 4ê°œ (1,620 lines)
- **Export íŒŒì¼**: 1ê°œ (15 lines)
- **TypeScript ì—ëŸ¬**: 0ê°œ âœ…
- **Lint ê²½ê³ **: 0ê°œ âœ…

---

## ğŸ¯ ì™„ë£Œ í•­ëª©

### 1. Custom Hook: useEvaluationHarness.ts (816 lines) âœ…

**ìœ„ì¹˜**: `frontend/src/hooks/useEvaluationHarness.ts`

**ì£¼ìš” ê¸°ëŠ¥**:

- í†µí•© í‰ê°€ ì‹œìŠ¤í…œ ìƒíƒœ ê´€ë¦¬
- ë²¤ì¹˜ë§ˆí¬, í‰ê°€ ì‘ì—…, A/B í…ŒìŠ¤íŠ¸, ê³µì •ì„± ê°ì‚¬ í†µí•©

**í•µì‹¬ êµ¬ì¡°**:

```typescript
// Main Hook (3 queries, 5 mutations)
export const useEvaluationHarness = () => {
  // Queries
  - benchmarksList: Benchmark[]
  - abTestsList: ABTest[]
  - fairnessList: FairnessReport[]

  // Mutations
  - createBenchmark()
  - runBenchmark()
  - createEvaluation()
  - createABTest()
  - requestFairnessAudit()
}

// Detail Hooks (6 sub-hooks)
1. useBenchmarkDetail(benchmarkId: string | null)
   - ë²¤ì¹˜ë§ˆí¬ ìƒì„¸ ì •ë³´ (test cases, models tested, average score)

2. useBenchmarkRun(runId: string | null)
   - ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ìƒíƒœ ì¶”ì 
   - Auto-refresh: 3ì´ˆ ê°„ê²© (status = running/pending)

3. useEvaluationJob(jobId: string | null)
   - í‰ê°€ ì‘ì—… ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
   - Auto-refresh: 5ì´ˆ ê°„ê²© (status = running/pending)
   - Metrics: confusion matrix, ROC curve, PR curve

4. useABTestDetail(testId: string | null)
   - A/B í…ŒìŠ¤íŠ¸ ìƒì„¸ (traffic split, statistical significance)
   - Auto-refresh: 5ì´ˆ ê°„ê²© (status = running/analyzing)

5. useFairnessReport(reportId: string | null)
   - ê³µì •ì„± ë¦¬í¬íŠ¸ (bias detection, fairness metrics, group metrics)
   - Auto-refresh: 5ì´ˆ ê°„ê²© (status = analyzing)

6. useEvaluationList()
   - ëª¨ë“  í‰ê°€ ì‘ì—… ëª©ë¡
   - Filters: status, date range
```

**Query Keys ê³„ì¸µ êµ¬ì¡°**:

```typescript
evaluationHarnessQueryKeys = {
  all: ['evaluation-harness']
  benchmarks: () => [...all, 'benchmarks']
  benchmarksList: () => [...benchmarks(), 'list']
  benchmarkDetail: (id) => [...benchmarks(), 'detail', id]
  benchmarkRun: (id) => [...benchmarks(), 'run', id]

  evaluations: () => [...all, 'evaluations']
  evaluationsList: () => [...evaluations(), 'list']
  evaluationJob: (id) => [...evaluations(), 'job', id]

  abTests: () => [...all, 'ab-tests']
  abTestDetail: (id) => [...abTests(), 'detail', id]

  fairness: () => [...all, 'fairness']
  fairnessReport: (id) => [...fairness(), 'report', id]
}
```

**íƒ€ì… ì •ì˜**:

```typescript
// 11ê°œ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- Benchmark (ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬)
- BenchmarkDetail (ìƒì„¸ + test cases)
- BenchmarkRun (ì‹¤í–‰ ìƒíƒœ + progress)
- BenchmarkResults (test results + summary)
- EvaluationJob (í‰ê°€ ì‘ì—…)
- EvaluationMetrics (confusion matrix, ROC, PR curves)
- ABTest (A/B í…ŒìŠ¤íŠ¸ ê¸°ë³¸)
- ABTestDetail (statistical significance í¬í•¨)
- FairnessReport (bias detection + fairness metrics)
  - bias_detected: { detected, severity, affected_groups }
  - group_metrics: Record<string, GroupMetric>
  - recommendations: string[]
- BenchmarkCreate, EvaluationJobCreate, ABTestCreate, FairnessAuditRequest
```

**Auto-Refresh ë¡œì§**:

```typescript
refetchInterval: (query) => {
  if (
    query.state.data?.status === "running" ||
    query.state.data?.status === "pending"
  ) {
    return 3000; // 3ì´ˆ (ë²¤ì¹˜ë§ˆí¬)
  }
  if (query.state.data?.status === "analyzing") {
    return 5000; // 5ì´ˆ (í‰ê°€/A/B/ê³µì •ì„±)
  }
  return false; // ì™„ë£Œ ì‹œ ì¤‘ì§€
};
```

---

### 2. Component 1: BenchmarkSuite.tsx (488 lines) âœ…

**ìœ„ì¹˜**: `frontend/src/components/mlops/evaluation-harness/BenchmarkSuite.tsx`

**ì£¼ìš” ê¸°ëŠ¥**:

- ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ê´€ë¦¬ ë° ì‹¤í–‰
- ë²¤ì¹˜ë§ˆí¬ ìƒì„± ë° ëª¨ë¸ ëŒ€ìƒ ì‹¤í–‰

**í•µì‹¬ UI êµ¬ì„±**:

```typescript
// 1. Benchmark List Table
<Table>
  Columns:
  - Name: ë²¤ì¹˜ë§ˆí¬ ì´ë¦„
  - Test Count: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜
  - Status: draft | active | archived (Chip)
  - Last Run: ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„
  - Result: success | failed | partial
  - Actions: View, Run, Edit

  Status Colors:
  - draft: default (grey)
  - active: success (green)
  - archived: warning (orange)
</Table>

// 2. Run Benchmark Dialog
<Dialog title="ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰">
  - Model Selection (required): Dropdown
  - Progress Tracking: LinearProgress (0-100%)
  - Status Alert: "ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘... X% ì™„ë£Œ"

  Flow:
  1. Select model
  2. Click "ì‹¤í–‰"
  3. Show progress bar
  4. Poll status every 3s (useBenchmarkRun)
  5. Display results on completion
</Dialog>

// 3. Create Benchmark Dialog
<Dialog title="ìƒˆ ë²¤ì¹˜ë§ˆí¬ ìƒì„±">
  - Name: TextField (required)
  - Description: TextField multiline
  - Test Cases Builder:
    - Add Test Case: Button
    - Test Case Form:
      * Name: TextField
      * Description: TextField
      * Expected Metrics: JSON input (accuracy, precision, etc.)
    - Remove Test Case: IconButton

  Dynamic Test Cases:
  - useState<TestCase[]>
  - Add: [...testCases, newCase]
  - Remove: testCases.filter((_, i) => i !== index)
</Dialog>
```

**ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í‘œì‹œ**:

```typescript
// useBenchmarkRun hookìœ¼ë¡œ 3ì´ˆë§ˆë‹¤ polling
{benchmarkRun?.status === 'running' && (
  <Alert severity="info">
    <Typography>ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘... {benchmarkRun.progress}% ì™„ë£Œ</Typography>
    <LinearProgress value={benchmarkRun.progress} />
  </Alert>
)}
```

**ìƒíƒœ ê´€ë¦¬**:

```typescript
const [selectedBenchmarkId, setSelectedBenchmarkId] = useState<string | null>(
  null
);
const [runDialogOpen, setRunDialogOpen] = useState(false);
const [createDialogOpen, setCreateDialogOpen] = useState(false);

const { benchmarksList, createBenchmark, runBenchmark } =
  useEvaluationHarness();

const { benchmarkDetail } = useBenchmarkDetail(selectedBenchmarkId);
const { benchmarkRun } = useBenchmarkRun(runId);
```

---

### 3. Component 2: EvaluationResults.tsx (442 lines) âœ…

**ìœ„ì¹˜**:
`frontend/src/components/mlops/evaluation-harness/EvaluationResults.tsx`

**ì£¼ìš” ê¸°ëŠ¥**:

- ìƒì„¸ í‰ê°€ ê²°ê³¼ ì‹œê°í™”
- Confusion Matrix, ROC Curve, PR Curve ì°¨íŠ¸

**í•µì‹¬ UI êµ¬ì„±**:

```typescript
// 1. Metrics Overview (5 cards in one row)
<Grid container spacing={2}>
  {[accuracy, precision, recall, f1, auc].map(metric => (
    <Grid size={{ xs: 12, sm: 6, md: 2.4 }}>
      <Card>
        <Typography variant="h3">{metric.value}</Typography>
        <Typography variant="caption">{metric.name}</Typography>
      </Card>
    </Grid>
  ))}
</Grid>

Grid Layout:
- xs: 12 (ëª¨ë°”ì¼: 1 card/row)
- sm: 6 (íƒœë¸”ë¦¿: 2 cards/row)
- md: 2.4 (ë°ìŠ¤í¬í†±: 5 cards/row, ì •í™•íˆ ê· ë“± ë¶„í• )

// 2. Visualization Tabs
<Tabs value={tabValue}>
  <Tab label="Confusion Matrix" />
  <Tab label="ROC Curve" />
  <Tab label="Precision-Recall Curve" />
</Tabs>

// Tab 1: Confusion Matrix Heatmap
<TabPanel value={0}>
  <ScatterChart data={confusionMatrixData}>
    - Xì¶•: Predicted Class
    - Yì¶•: Actual Class
    - Color: Value intensity (red = high, green = low)
    - Cell Size: Fixed 50px
    - Helper: getColorForValue(value, max)
      * Red-Green gradient: rgb(255-scale, scale, 0)
  </ScatterChart>

  Data Transform:
  getConfusionMatrixHeatmapData(matrix: number[][]):
    matrix.flatMap((row, y) =>
      row.map((value, x) => ({
        x: classLabels[x],
        y: classLabels[y],
        value: value,
        color: getColorForValue(value, max)
      }))
    )
</TabPanel>

// Tab 2: ROC Curve
<TabPanel value={1}>
  <LineChart>
    - Data: [{ fpr, tpr }] (from roc_curve)
    - Reference Line: Diagonal (random classifier)
    - AUC Display: Typography with value
    - Axes: FPR (x), TPR (y)
  </LineChart>

  Display:
  - Blue Line: Actual ROC curve
  - Red Dashed Line: Random classifier (y=x)
  - Legend: "ROC Curve (AUC: 0.92)"
</TabPanel>

// Tab 3: Precision-Recall Curve
<TabPanel value={2}>
  <LineChart>
    - Data: [{ recall, precision }]
    - No reference line
    - Axes: Recall (x), Precision (y)
  </LineChart>
</TabPanel>
```

**ë°ì´í„° ë³€í™˜ ë¡œì§**:

```typescript
// Confusion Matrix Heatmap ë³€í™˜
const getConfusionMatrixHeatmapData = (matrix: number[][]) => {
  const max = Math.max(...matrix.flat());
  return matrix.flatMap((row, y) =>
    row.map((value, x) => ({
      x: classLabels[x],
      y: classLabels[y],
      value: value,
      fill: getColorForValue(value, max),
    }))
  );
};

// ìƒ‰ìƒ ê³„ì‚° (0-255 ìŠ¤ì¼€ì¼)
const getColorForValue = (value: number, max: number): string => {
  const scale = Math.round((value / max) * 255);
  return `rgb(${255 - scale}, ${scale}, 0)`;
};
```

**ìë™ ìƒˆë¡œê³ ì¹¨**:

```typescript
const { evaluationJob } = useEvaluationJob(jobId);
// statusê°€ 'running' ë˜ëŠ” 'pending'ì¼ ë•Œ 5ì´ˆë§ˆë‹¤ ìë™ polling
```

**ì¶”ê°€ ì •ë³´ í‘œì‹œ**:

```typescript
<Box>
  - Evaluation Time: completed_at - created_at
  - Class Count: classLabels.length
  - Total Samples: confusion_matrix.reduce(sum)
</Box>
```

---

### 4. Component 3: ABTestingPanel.tsx (642 lines) âœ…

**ìœ„ì¹˜**: `frontend/src/components/mlops/evaluation-harness/ABTestingPanel.tsx`

**ì£¼ìš” ê¸°ëŠ¥**:

- A/B í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ (4ë‹¨ê³„)
- í†µê³„ì  ìœ ì˜ì„± ë¶„ì„ ë° ê²°ê³¼ ë¹„êµ

**í•µì‹¬ UI êµ¬ì„±**:

```typescript
// 1. Stepper (4 stages)
<Stepper activeStep={getStageIndex(abTestDetail.stage)}>
  <Step><StepLabel>ì„¤ì •</StepLabel></Step>
  <Step><StepLabel>ì‹¤í–‰</StepLabel></Step>
  <Step><StepLabel>ë¶„ì„</StepLabel></Step>
  <Step><StepLabel>ê²°ì •</StepLabel></Step>
</Stepper>

Stage Mapping:
- setup â†’ 0
- run â†’ 1
- analyze â†’ 2
- decide â†’ 3

Status Colors:
- setup: default
- running: primary (blue)
- analyzing: secondary (purple)
- completed: success (green)
- decided: success

// 2. Model Comparison Cards
<Grid container spacing={2}>
  <Grid size={{ xs: 12, md: 6 }}>
    <Card>
      <Typography variant="subtitle2">Model A</Typography>
      <Typography variant="h6">{model_a_name}</Typography>
      <Typography variant="caption">
        íŠ¸ë˜í”½: {traffic_split.model_a}%
      </Typography>
    </Card>
  </Grid>
  <Grid size={{ xs: 12, md: 6 }}>
    <Card>
      <Typography variant="subtitle2">Model B</Typography>
      <Typography variant="h6">{model_b_name}</Typography>
      <Typography variant="caption">
        íŠ¸ë˜í”½: {traffic_split.model_b}%
      </Typography>
    </Card>
  </Grid>
</Grid>

// 3. Results Comparison Table
<Table>
  Columns:
  - Metric: accuracy, precision, recall, f1, auc
  - Model A: value (4 decimal)
  - Model B: value (4 decimal)
  - Difference: Chip (color-coded)
    * Green: diff > 0 (Model A better)
    * Red: diff < 0 (Model B better)
    * Format: "+0.0234" or "-0.0156"
</Table>

// 4. Statistical Significance Alert
<Alert severity={significance ? "success" : "warning"}>
  í†µê³„ì  ìœ ì˜ì„±: {significance ? "ìœ ì˜í•¨" : "ìœ ì˜í•˜ì§€ ì•ŠìŒ"}
  p-value: 0.0123 | Effect Size: 0.456

  Icon:
  - Significant: <CheckCircleIcon />
  - Not Significant: (default warning icon)
</Alert>

// 5. Winner Declaration (if decided)
<Card variant="outlined" sx={{ bgcolor: 'success.light' }}>
  <Box sx={{ display: 'flex', alignItems: 'center' }}>
    <GavelIcon />
    <Typography variant="subtitle2">ìµœì¢… ê²°ì •</Typography>
    <Chip label={winnerLabel} color={winnerColor} />
  </Box>
</Card>

Winner Labels:
- "a": "Model A ìŠ¹ë¦¬" (success)
- "b": "Model B ìŠ¹ë¦¬" (error)
- "tie": "ë¬´ìŠ¹ë¶€" (warning)

// 6. Create A/B Test Dialog
<Dialog title="ìƒˆ A/B í…ŒìŠ¤íŠ¸ ìƒì„±">
  - Name: TextField (required)
  - Description: TextField multiline
  - Model A: Select (required)
  - Model B: Select (required, disabled if === model_a_id)
  - Traffic Split A: TextField number (0-100, step 5)
    * Helper text: "Model B: {100 - split_a}%"
  - Sample Size: TextField number (min 100, step 100)
  - Confidence Level: Select
    * 90% (0.90)
    * 95% (0.95) - default
    * 99% (0.99)

  Validation:
  - Disable submit if:
    * !name
    * !model_a_id
    * !model_b_id
    * model_a_id === model_b_id
</Dialog>
```

**ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©**:

```typescript
{abTestDetail.status === 'running' && (
  <Box>
    <Typography variant="body2">í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘...</Typography>
    <LinearProgress />
  </Box>
)}

// useABTestDetail hookìœ¼ë¡œ 5ì´ˆë§ˆë‹¤ polling
```

**Helper Functions**:

```typescript
const getStageIndex = (stage: string): number => {
  const stages = ["setup", "run", "analyze", "decide"];
  return stages.indexOf(stage);
};

const getStatusColor = (status: string): ChipColor => {
  const colorMap = {
    setup: "default",
    running: "primary",
    analyzing: "secondary",
    completed: "success",
    decided: "success",
  };
  return colorMap[status] || "default";
};

const getWinnerLabel = (winner: "a" | "b" | "tie"): string => {
  const labelMap = {
    a: "Model A ìŠ¹ë¦¬",
    b: "Model B ìŠ¹ë¦¬",
    tie: "ë¬´ìŠ¹ë¶€",
  };
  return labelMap[winner];
};

const getWinnerColor = (winner: "a" | "b" | "tie"): ChipColor => {
  const colorMap = {
    a: "success",
    b: "error",
    tie: "warning",
  };
  return colorMap[winner];
};
```

**í…ŒìŠ¤íŠ¸ ì„¤ì • ì •ë³´**:

```typescript
<Box>
  - Sample Size: 1,000 (toLocaleString)
  - Confidence Level: 95%
  - Created At: 2025-01-XX XX:XX:XX (ko-KR locale)
</Box>
```

---

### 5. Component 4: FairnessAuditor.tsx (539 lines) âœ…

**ìœ„ì¹˜**: `frontend/src/components/mlops/evaluation-harness/FairnessAuditor.tsx`

**ì£¼ìš” ê¸°ëŠ¥**:

- ëª¨ë¸ í¸í–¥ ê°ì§€ ë° ê³µì •ì„± ë©”íŠ¸ë¦­ ì‹œê°í™”
- ê·¸ë£¹ë³„ ì„±ëŠ¥ ë¹„êµ ë° ê°œì„  ê¶Œì¥ì‚¬í•­

**í•µì‹¬ UI êµ¬ì„±**:

```typescript
// 1. Bias Detection Alert
<Alert severity={getBiasSeverityColor(severity)} icon={icon}>
  í¸í–¥ ê°ì§€: {bias_detected.detected ? "ì˜ˆ" : "ì•„ë‹ˆì˜¤"}
  ì‹¬ê°ë„: {severity.toUpperCase()} | ì˜í–¥ë°›ì€ ê·¸ë£¹: {affected_groups.join(', ')}
</Alert>

Severity Colors & Icons:
- low: success (green) + <CheckCircleIcon />
- medium: warning (orange) + <WarningIcon />
- high: error (red) + <ErrorIcon />
- critical: error (red) + <ErrorIcon />

// 2. Fairness Metrics Radar Chart
<ResponsiveContainer width="100%" height={400}>
  <RadarChart data={radarData}>
    <PolarGrid />
    <PolarAngleAxis dataKey="metric" />
    <PolarRadiusAxis domain={[0, 1]} />
    <Radar
      name="ê³µì •ì„± ì ìˆ˜"
      dataKey="value"
      stroke="#8884d8"
      fill="#8884d8"
      fillOpacity={0.6}
    />
    <Legend />
  </RadarChart>
</ResponsiveContainer>

Radar Data Transform:
getRadarChartData() => [
  { metric: "ì¸êµ¬í†µê³„í•™ì  ë™ë“±ì„±", value: 0.75, fullMark: 1.0 },
  { metric: "ë™ë“±í•œ ê¸°íšŒ", value: 0.82, fullMark: 1.0 },
  { metric: "ê· ë“±í™”ëœ í™•ë¥ ", value: 0.78, fullMark: 1.0 },
  { metric: "ì°¨ë³„ì  ì˜í–¥", value: 0.70, fullMark: 1.0 },
]

Metric Name Mapping:
- demographic_parity â†’ "ì¸êµ¬í†µê³„í•™ì  ë™ë“±ì„±"
- equal_opportunity â†’ "ë™ë“±í•œ ê¸°íšŒ"
- equalized_odds â†’ "ê· ë“±í™”ëœ í™•ë¥ "
- disparate_impact â†’ "ì°¨ë³„ì  ì˜í–¥"

Chart Note:
"* 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê³µì •í•¨ (ì„ê³„ê°’: 0.8)"

// 3. Group Metrics Comparison Table
<Table>
  Columns:
  - Group: Group name (bold)
  - Accuracy: 4 decimal
  - Precision: 4 decimal
  - Recall: 4 decimal
  - FPR: False Positive Rate (4 decimal)
  - FNR: False Negative Rate (4 decimal)

  Data Source:
  Object.entries(group_metrics).map(([group, metrics]) => ...)

  Example:
  | Group   | Accuracy | Precision | Recall | FPR    | FNR    |
  |---------|----------|-----------|--------|--------|--------|
  | Group A | 0.8800   | 0.9000    | 0.8500 | 0.1000 | 0.1500 |
  | Group B | 0.8200   | 0.8500    | 0.7800 | 0.1500 | 0.2200 |
</Table>

// 4. Recommendations Section
{recommendations && recommendations.length > 0 && (
  <Box>
    <Typography variant="h6">ê¶Œì¥ ì‚¬í•­</Typography>
    {recommendations.map((rec, index) => (
      <Alert key={index} severity="info" variant="outlined">
        {rec}
      </Alert>
    ))}
  </Box>
)}

Example Recommendations:
- "ë°ì´í„° ì¬ìƒ˜í”Œë§ì„ í†µí•´ ê·¸ë£¹ ê°„ ê· í˜•ì„ ê°œì„ í•˜ì„¸ìš”"
- "ëª¨ë¸ í•™ìŠµ ì‹œ ê³µì •ì„± ì œì•½ì„ ì¶”ê°€í•˜ì„¸ìš”"

// 5. Audit Information
<Box>
  - Protected Attributes: [Chip array]
    * gender, age, race, ethnicity
  - Fairness Threshold: 0.8
  - Created At: 2025-01-XX XX:XX:XX (ko-KR)
</Box>

// 6. Request Fairness Audit Dialog
<Dialog title="ê³µì •ì„± ê°ì‚¬ ìš”ì²­">
  - Model: Select (required)
  - Protected Attributes: Multi-Select (required)
    * Chip display for selected items
    * Options: gender, age, race, ethnicity
  - Fairness Threshold: Select
    * 0.7 (ë‚®ìŒ)
    * 0.8 (ì¤‘ê°„) - default
    * 0.9 (ë†’ìŒ)
    * 0.95 (ë§¤ìš° ë†’ìŒ)

  Validation:
  - Disable submit if:
    * !model_id
    * protected_attributes.length === 0
</Dialog>
```

**Helper Functions**:

```typescript
const getBiasSeverityColor = (severity: Severity): ChipColor => {
  const colorMap = {
    low: 'success',
    medium: 'warning',
    high: 'error',
    critical: 'error',
  };
  return colorMap[severity];
};

const getBiasSeverityIcon = (severity: Severity) => {
  const iconMap = {
    low: <CheckCircleIcon />,
    medium: <WarningIcon />,
    high: <ErrorIcon />,
    critical: <ErrorIcon />,
  };
  return iconMap[severity];
};

const formatFairnessMetricName = (metric: string): string => {
  const nameMap: Record<string, string> = {
    demographic_parity: 'ì¸êµ¬í†µê³„í•™ì  ë™ë“±ì„±',
    equal_opportunity: 'ë™ë“±í•œ ê¸°íšŒ',
    equalized_odds: 'ê· ë“±í™”ëœ í™•ë¥ ',
    disparate_impact: 'ì°¨ë³„ì  ì˜í–¥',
  };
  return nameMap[metric] || metric.replace(/_/g, ' ').toUpperCase();
};

const getRadarChartData = () => {
  if (!fairnessReport?.fairness_metrics) return [];

  return Object.entries(fairnessReport.fairness_metrics).map(
    ([metric, value]) => ({
      metric: formatFairnessMetricName(metric),
      value: value,
      fullMark: 1.0,
    })
  );
};
```

**íƒ€ì… êµ¬ì¡° (FairnessReport)**:

```typescript
interface FairnessReport {
  id: string;
  model_id: string;
  model_name: string;
  created_at: string;
  status: "analyzing" | "completed" | "failed";

  bias_detected: {
    detected: boolean;
    severity: "low" | "medium" | "high" | "critical";
    affected_groups: string[];
  };

  protected_attributes: string[];
  fairness_threshold: number;

  fairness_metrics: {
    demographic_parity: number;
    equal_opportunity: number;
    equalized_odds: number;
    disparate_impact: number;
  };

  group_metrics: Record<
    string,
    {
      group_name: string;
      accuracy: number;
      precision: number;
      recall: number;
      fpr: number; // False Positive Rate
      fnr: number; // False Negative Rate
    }
  >;

  recommendations: string[];

  alerts: {
    severity: "low" | "medium" | "high" | "critical";
    metric: string;
    message: string;
  }[];
}
```

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

### Frontend Technologies

- **React 19**: Functional components with hooks
- **TypeScript 5**: Strict type safety
- **TanStack Query v5**: Server state management with auto-refresh
- **Material-UI v6**: UI components (Card, Table, Dialog, Stepper, Chip, Alert)
- **recharts v2.10.0**: Data visualization
  - ScatterChart: Confusion Matrix heatmap
  - LineChart: ROC Curve, PR Curve
  - RadarChart: Fairness metrics
- **Grid v7**: Responsive layout (`size={{ xs, sm, md }}`)
- **Biome**: Code formatting and linting

### Query Optimization

```typescript
// Stale Time
- Benchmarks: 5ë¶„ (ë³€ê²½ ë¹ˆë„ ë‚®ìŒ)
- A/B Tests: 2ë¶„ (ì§„í–‰ ì¤‘ í…ŒìŠ¤íŠ¸ ëª¨ë‹ˆí„°ë§)
- Fairness Reports: 5ë¶„ (ë¶„ì„ ì™„ë£Œ í›„ ë³€ê²½ ì—†ìŒ)

// Auto-Refresh (refetchInterval)
- Benchmark Run: 3ì´ˆ (status = running/pending)
- Evaluation Job: 5ì´ˆ (status = running/pending)
- A/B Test: 5ì´ˆ (status = running/analyzing)
- Fairness Report: 5ì´ˆ (status = analyzing)

// Cache Invalidation
- createBenchmark â†’ invalidate benchmarks()
- runBenchmark â†’ invalidate benchmarks(), benchmarkDetail()
- createEvaluation â†’ invalidate evaluations()
- createABTest â†’ invalidate abTests()
- requestFairnessAudit â†’ invalidate fairness()
```

### UI/UX Patterns

```typescript
// Grid Layout
<Grid container spacing={2}>
  <Grid size={{ xs: 12, sm: 6, md: 2.4 }}> // 5-column on desktop
  <Grid size={{ xs: 12, md: 6 }}>         // 2-column on desktop
</Grid>

// Status Chips
<Chip label="RUNNING" color="primary" />
<Chip label="COMPLETED" color="success" />
<Chip label="HIGH" color="error" />

// Progress Indicators
<LinearProgress />                          // Indeterminate
<LinearProgress value={progress} />        // Determinate (0-100)

// Dialogs
<Dialog maxWidth="md" fullWidth>           // Medium width, responsive
  <DialogTitle>...</DialogTitle>
  <DialogContent>...</DialogContent>
  <DialogActions>...</DialogActions>
</Dialog>

// Tables
<TableContainer component={Paper} variant="outlined">
  <Table>
    <TableHead>...</TableHead>
    <TableBody>...</TableBody>
  </Table>
</TableContainer>

// Alerts
<Alert severity="success|warning|error|info" icon={<Icon />}>
  <Typography variant="body2">...</Typography>
</Alert>
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
frontend/src/
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useEvaluationHarness.ts          (816 lines) âœ…
â”‚       â”œâ”€â”€ Main Hook (3 queries, 5 mutations)
â”‚       â”œâ”€â”€ 6 Detail Hooks (Benchmark, Run, Evaluation, ABTest, Fairness, List)
â”‚       â”œâ”€â”€ 11 TypeScript Interfaces
â”‚       â””â”€â”€ Query Keys ê³„ì¸µ êµ¬ì¡°
â”‚
â””â”€â”€ components/mlops/evaluation-harness/
    â”œâ”€â”€ BenchmarkSuite.tsx               (488 lines) âœ…
    â”‚   â”œâ”€â”€ Benchmark List Table
    â”‚   â”œâ”€â”€ Run Dialog (progress tracking)
    â”‚   â””â”€â”€ Create Dialog (test case builder)
    â”‚
    â”œâ”€â”€ EvaluationResults.tsx            (442 lines) âœ…
    â”‚   â”œâ”€â”€ 5 Metric Cards (Grid 2.4 layout)
    â”‚   â”œâ”€â”€ Tab 1: Confusion Matrix (ScatterChart)
    â”‚   â”œâ”€â”€ Tab 2: ROC Curve (LineChart)
    â”‚   â””â”€â”€ Tab 3: PR Curve (LineChart)
    â”‚
    â”œâ”€â”€ ABTestingPanel.tsx               (642 lines) âœ…
    â”‚   â”œâ”€â”€ 4-Stage Stepper
    â”‚   â”œâ”€â”€ Model Comparison Cards
    â”‚   â”œâ”€â”€ Results Table (side-by-side metrics)
    â”‚   â”œâ”€â”€ Statistical Significance Alert
    â”‚   â”œâ”€â”€ Winner Declaration Card
    â”‚   â””â”€â”€ Create Dialog (traffic split config)
    â”‚
    â”œâ”€â”€ FairnessAuditor.tsx              (539 lines) âœ…
    â”‚   â”œâ”€â”€ Bias Detection Alert
    â”‚   â”œâ”€â”€ Fairness Metrics RadarChart
    â”‚   â”œâ”€â”€ Group Metrics Table
    â”‚   â”œâ”€â”€ Recommendations (Alert array)
    â”‚   â””â”€â”€ Request Dialog (multi-select attributes)
    â”‚
    â””â”€â”€ index.ts                         (15 lines) âœ…
        â””â”€â”€ Export all 4 components
```

---

## ğŸ§ª í’ˆì§ˆ ê²€ì¦

### TypeScript Compilation

```bash
âœ… 0 errors in 6 files
- useEvaluationHarness.ts: No errors
- BenchmarkSuite.tsx: No errors
- EvaluationResults.tsx: No errors
- ABTestingPanel.tsx: No errors
- FairnessAuditor.tsx: No errors
- index.ts: No errors
```

### Code Formatting

```bash
âœ… Biome formatting applied
- Fixed 5 files in final pass
- Total formatted: 480 files
```

### Lint Errors Fixed

```bash
During implementation:
1. BenchmarkSuite.tsx: Removed unused variables (isLoadingDetail, isLoadingRun)
2. ABTestingPanel.tsx: Removed unused import (AnalyticsIcon), removed unused function (handleTrafficSplitChange)
3. FairnessAuditor.tsx: Removed unused import (Grid)
4. useEvaluationHarness.ts: Fixed FairnessReport type structure (bias_detected, group_metrics)
```

### Type Safety Improvements

```typescript
// Before (incorrect)
interface FairnessReport {
  bias_detected: boolean; // âŒ
  group_metrics: []; // âŒ
}

// After (correct)
interface FairnessReport {
  bias_detected: {
    // âœ…
    detected: boolean;
    severity: "low" | "medium" | "high" | "critical";
    affected_groups: string[];
  };
  group_metrics: Record<
    // âœ…
    string,
    {
      group_name: string;
      accuracy: number;
      precision: number;
      recall: number;
      fpr: number;
      fnr: number;
    }
  >;
  protected_attributes: string[]; // âœ… Added
  fairness_threshold: number; // âœ… Added
  recommendations: string[]; // âœ… Added
}
```

---

## ğŸ¯ í•µì‹¬ ê¸°ëŠ¥

### 1. Benchmark Testing

```typescript
Features:
- Create benchmark suites with multiple test cases
- Run benchmarks against any model
- Track execution progress in real-time (3s polling)
- View detailed results with pass/fail status
- Compare models across standardized tests

Use Cases:
- Regression testing after model updates
- Model quality gates before deployment
- Performance comparison across model versions
```

### 2. Model Evaluation

```typescript
Features:
- Comprehensive metrics (accuracy, precision, recall, F1, AUC)
- Confusion matrix heatmap visualization
- ROC curve with reference diagonal
- Precision-Recall curve
- Auto-refresh during evaluation (5s polling)

Use Cases:
- Detailed model performance analysis
- Class-wise performance breakdown
- Model selection based on visual metrics
```

### 3. A/B Testing

```typescript
Features:
- 4-stage workflow (Setup â†’ Run â†’ Analyze â†’ Decide)
- Configurable traffic split (0-100%)
- Statistical significance testing (p-value, effect size)
- Side-by-side metric comparison
- Winner declaration with confidence level

Use Cases:
- Safe model rollout (gradual traffic increase)
- Data-driven model selection
- Minimize production risk
```

### 4. Fairness Auditing

```typescript
Features:
- Bias detection across protected attributes
- 4 fairness metrics (radar chart visualization)
- Group-wise performance comparison
- Severity-based alerts (low/medium/high/critical)
- Actionable recommendations

Use Cases:
- Regulatory compliance (GDPR, AI Act)
- Ethical AI deployment
- Bias mitigation before production
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### Query Strategies

```typescript
1. Selective Polling:
   - Only poll when status is in-progress
   - Stop polling on completion/failure
   - Prevent unnecessary API calls

2. Hierarchical Keys:
   - Granular invalidation (invalidate specific detail, not all)
   - Efficient cache updates

3. Stale Time:
   - Balance between freshness and API load
   - 2-5 minutes for completed data

4. Lazy Loading:
   - Detail queries only fetch when ID is provided
   - Avoid loading all details upfront
```

### UI Optimizations

```typescript
1. Grid Responsive Layout:
   - Mobile-first design (xs: 12)
   - Adaptive columns (md: 2.4 for 5 cards)
   - Smooth breakpoint transitions

2. Chart Data Transformation:
   - Memoized helper functions
   - Minimize recalculations on re-renders

3. Conditional Rendering:
   - Show progress only when running
   - Load charts only on tab activation
```

---

## ğŸ”„ ë‹¤ìŒ ë‹¨ê³„ (Phase 4 Day 7-8)

### 7ì¼ì°¨: AI í†µí•© ì‹œìŠ¤í…œ (MLOps + LLM)

- AutoML íŒŒì´í”„ë¼ì¸ ìë™í™”
- Hyperparameter tuning (Optuna í†µí•©)
- LLM ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ì–´ì‹œìŠ¤í„´íŠ¸
- ìì—°ì–´ ì¿¼ë¦¬ â†’ SQL ë³€í™˜

### 8ì¼ì°¨: ëŒ€ì‹œë³´ë“œ í†µí•© ë° ìµœì¢… ê²€ì¦

- í†µí•© MLOps ëŒ€ì‹œë³´ë“œ
- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
- ì•Œë¦¼ ì‹œìŠ¤í…œ (Slack/Email)
- Phase 4 ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸

---

## ğŸ“ ê°œë°œ ë…¸íŠ¸

### ì£¼ìš” ê²°ì • ì‚¬í•­

1. **Fairness Report íƒ€ì… ê°œì„ **:

   - `bias_detected`ë¥¼ boolean â†’ êµ¬ì¡°í™”ëœ ê°ì²´ë¡œ ë³€ê²½
   - `group_metrics`ë¥¼ ë°°ì—´ â†’ Record<string, Metric>ìœ¼ë¡œ ë³€ê²½ (key-based access)
   - `protected_attributes`, `fairness_threshold`, `recommendations` ì¶”ê°€

2. **Chart ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ**:

   - recharts ì±„íƒ ì´ìœ :
     - Material-UIì™€ ì˜ í†µí•©ë¨
     - ScatterChart (Confusion Matrix heatmap)
     - RadarChart (Fairness metrics)
     - ê°„ë‹¨í•œ API, ë°˜ì‘í˜• ë””ìì¸

3. **Grid Layout íŒ¨í„´**:

   - Material-UI Grid v7 ì‚¬ìš© (size prop)
   - 5-column layout: `size={{ xs: 12, sm: 6, md: 2.4 }}`
   - ì •í™•í•œ ê· ë“± ë¶„í•  (2.4 \* 5 = 12)

4. **Auto-Refresh ì „ëµ**:
   - ë²¤ì¹˜ë§ˆí¬: 3ì´ˆ (ì§§ì€ ì£¼ê¸°, ë¹ ë¥¸ ì‹¤í–‰)
   - í‰ê°€/A/B/ê³µì •ì„±: 5ì´ˆ (ê¸´ ì£¼ê¸°, ê¸´ ë¶„ì„)
   - ìƒíƒœ ê¸°ë°˜ ì¡°ê±´ë¶€ polling

### ì•Œë ¤ì§„ ì œí•œì‚¬í•­

1. **Mock Data ì‚¬ìš©**:

   - ëª¨ë“  API í˜¸ì¶œì´ mock êµ¬í˜„
   - ì‹¤ì œ ë°±ì—”ë“œ API ì—°ê²° í•„ìš”
   - `pnpm gen:client` í›„ íƒ€ì… êµì²´ ì˜ˆì •

2. **ì°¨íŠ¸ ì„±ëŠ¥**:

   - ëŒ€ê·œëª¨ confusion matrix (100x100 ì´ìƒ) ì‹œ ë Œë”ë§ ì§€ì—° ê°€ëŠ¥
   - í•„ìš” ì‹œ virtualization ì ìš© ê³ ë ¤

3. **A/B Test í†µê³„**:
   - p-value, effect size ê³„ì‚°ì€ ë°±ì—”ë“œì—ì„œ ìˆ˜í–‰
   - í”„ë¡ íŠ¸ì—”ë“œëŠ” ê²°ê³¼ë§Œ í‘œì‹œ

---

## âœ… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] useEvaluationHarness.ts í›… ìƒì„± (816 lines)

  - [x] Main hook (3 queries, 5 mutations)
  - [x] 6 detail hooks (Benchmark, Run, Evaluation, ABTest, Fairness, List)
  - [x] Query keys ê³„ì¸µ êµ¬ì¡°
  - [x] Auto-refresh ë¡œì§
  - [x] 11ê°œ TypeScript ì¸í„°í˜ì´ìŠ¤

- [x] BenchmarkSuite.tsx ì»´í¬ë„ŒíŠ¸ (488 lines)

  - [x] Benchmark list table
  - [x] Run dialog with progress
  - [x] Create dialog with test case builder
  - [x] Real-time status updates

- [x] EvaluationResults.tsx ì»´í¬ë„ŒíŠ¸ (442 lines)

  - [x] 5 metric cards (Grid 2.4 layout)
  - [x] Confusion Matrix (ScatterChart heatmap)
  - [x] ROC Curve (LineChart)
  - [x] PR Curve (LineChart)

- [x] ABTestingPanel.tsx ì»´í¬ë„ŒíŠ¸ (642 lines)

  - [x] 4-stage Stepper
  - [x] Model comparison cards
  - [x] Results comparison table
  - [x] Statistical significance alert
  - [x] Winner declaration
  - [x] Create dialog with traffic split

- [x] FairnessAuditor.tsx ì»´í¬ë„ŒíŠ¸ (539 lines)

  - [x] Bias detection alert
  - [x] Fairness metrics RadarChart
  - [x] Group metrics table
  - [x] Recommendations section
  - [x] Request dialog

- [x] index.ts ìƒì„± (15 lines)

- [x] TypeScript ì—ëŸ¬ ìˆ˜ì •

  - [x] FairnessReport íƒ€ì… ì¬êµ¬ì¡°í™”
  - [x] ëª¨ë“  ì»´í¬ë„ŒíŠ¸ 0 ì—ëŸ¬

- [x] Lint ì—ëŸ¬ ìˆ˜ì •

  - [x] Unused imports ì œê±°
  - [x] Unused variables ì œê±°
  - [x] Unused functions ì œê±°

- [x] Biome í¬ë§·íŒ… ì ìš©

  - [x] ìµœì¢… í¬ë§·íŒ… ì™„ë£Œ

- [x] í’ˆì§ˆ ê²€ì¦
  - [x] 0 TypeScript ì—ëŸ¬
  - [x] 0 Lint ê²½ê³ 
  - [x] ì½”ë“œ í¬ë§·íŒ… ì™„ë£Œ

---

## ğŸ‰ Phase 4 Day 5-6 ì™„ë£Œ!

**ì´ ì½”ë“œ**: 2,451 lines  
**íŒŒì¼ ìˆ˜**: 6ê°œ  
**TypeScript ì—ëŸ¬**: 0ê°œ âœ…  
**Lint ê²½ê³ **: 0ê°œ âœ…

Phase 4 ëˆ„ì : 6,848 lines (Day 1-6)

- Day 1-2: 2,050 lines (Feature Store)
- Day 3-4: 2,347 lines (Model Lifecycle)
- Day 5-6: 2,451 lines (Evaluation Harness) â† í˜„ì¬

**ë‹¤ìŒ**: Phase 4 Day 7-8 - AI Integration System ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ! ğŸš€
